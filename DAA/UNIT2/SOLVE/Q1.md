<img width="665" height="507" alt="image" src="https://github.com/user-attachments/assets/52b0f54d-da69-4070-8ca2-bf47d58c23e9" />


The time complexity of the provided selection sort algorithm is **$O(n^2)$**.

***

## Analysis

The complexity is determined by analyzing the number of times the basic operations are executed, particularly within the nested loops. The most frequent operation is the comparison `if(A[j] < min_val)`.

1.  **Outer Loop**: The outer `for` loop runs from `i = 1` to `n-1`. This means it executes a total of **$(n-1)$ times**.

2.  **Inner Loop**: The inner `for` loop runs from `j = i+1` to `n`. The number of times it executes depends on the value of `i` from the outer loop:
    * When `i = 1`, the inner loop runs from `j = 2` to `n`, which is $(n - 2 + 1) = n-1$ times.
    * When `i = 2`, the inner loop runs from `j = 3` to `n`, which is $(n - 3 + 1) = n-2$ times.
    * ...
    * When `i = n-1`, the inner loop runs from `j = n` to `n`, which is $1$ time.

To find the total number of comparisons, we sum the iterations of the inner loop for each step of the outer loop:
$$\text{Total Comparisons} = (n-1) + (n-2) + \dots + 2 + 1$$
This is the sum of the first $(n-1)$ integers, which can be calculated using the formula for an arithmetic series, $\frac{k(k+1)}{2}$, where $k = n-1$.
$$\text{Total Comparisons} = \frac{(n-1)((n-1)+1)}{2} = \frac{(n-1)n}{2} = \frac{n^2 - n}{2}$$
The number of swaps (the two assignment statements after the inner loop) is performed once for each iteration of the outer loop. Therefore, there are **$n-1$** swaps.

The total time complexity, $T(n)$, is the sum of the comparisons and swaps:
$$T(n) = (\text{cost of comparison}) \times \frac{n^2 - n}{2} + (\text{cost of swap}) \times (n-1)$$
In Big-O notation, we only consider the highest-order term and ignore constants. The dominant term is $n^2$.

Therefore, the overall time complexity is **$O(n^2)$**. This holds true for the **best-case, average-case, and worst-case scenarios** because the nested loops will always run the same number of times regardless of the initial order of the elements in the array.

***

## Assumptions

1.  **`n`** represents the number of elements in the array `A`.
2.  The fundamental operations like **comparison (`<`)**, **assignment (`=`)**, and **arithmetic (`+`, `-`)** each take a constant amount of time to execute.
3.  The array `A` can fit into the main memory.
4.  The pseudocode uses **1-based indexing** (i.e., array indices run from 1 to `n`), as suggested by the loop initializations (`i=1`, `j=i+1`). The complexity remains $O(n^2)$ even with 0-based indexing.
